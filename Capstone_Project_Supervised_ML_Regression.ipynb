{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prashikdhole/ML_Project-on_Retail_sales_Predicton/blob/main/Capstone_Project_Supervised_ML_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Retail Sales Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Team\n",
        "##### **Team Member 1 -** Dipak Patle\n",
        "##### **Team Member 2 -** Prashik Dhole"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "This dataset is a live dataset of Rossmann Stores. On analysing this problem we observe that Rossmann problem is a regression problem and our primary goal is to predict the sales figures of Rossmann problem. In this Notebook we work on following topics 4\n",
        "\n",
        "Analysing the Dataset by using Exploratory Data Analysis. Using Exponential Moving Averages analyse Trends and Seasonality in Roseman dataset. Analyse Regression analysis using following prediction analysis,\n",
        "\n",
        "A. Linear Regression Analysis\n",
        "\n",
        "B. Elastic Regression (Lasso and Ridge Regression).\n",
        "\n",
        "C. Random Forest Regression.\n",
        "\n",
        "D. adaboost and Xgboost.\n",
        "\n",
        "By applying above algorthim we find accuracy of 98% by xgboost."
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -** https://github.com/Prashikdhole/ML_Project-on_Retail_sales_Predicton.git"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n",
        "\n",
        "Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied.\n",
        "You are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set. Note that some stores in the dataset were temporarily closed for refurbishment.\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "import missingno as msno\n",
        "import matplotlib\n",
        "import matplotlib.pylab as pylab\n",
        "\n",
        "%matplotlib inline\n",
        "matplotlib.style.use('ggplot')\n",
        "sns.set_style('white')\n",
        "pylab.rcParams['figure.figsize'] = 8,6\n",
        "\n",
        "import math\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.linear_model import LassoLars\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import ElasticNet"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mounting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rossman_df= pd.read_csv('/content/drive/MyDrive/Rossmann Stores Data.csv', low_memory= False)\n",
        "store_df=pd.read_csv('/content/drive/MyDrive/store (1).csv', low_memory= False)"
      ],
      "metadata": {
        "id": "nPrCd4POsfjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "rossman_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "RVZkpYad2czk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rossman_df.shape"
      ],
      "metadata": {
        "id": "KdHwnp9rz-86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.shape"
      ],
      "metadata": {
        "id": "Uv4eslnB0EGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dataset Information"
      ],
      "metadata": {
        "id": "SIVlaXCh0JLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rossman_df.info()"
      ],
      "metadata": {
        "id": "V0lWtP2ns5xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rossman_df.tail()"
      ],
      "metadata": {
        "id": "i0isNDMitG9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rossman_df.describe()"
      ],
      "metadata": {
        "id": "y4H4GV_LtLLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.info()"
      ],
      "metadata": {
        "id": "43S7hGA80p-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.describe()"
      ],
      "metadata": {
        "id": "8YZq3FLp0urs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "YSWzV89J1pFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rossman_df[rossman_df.duplicated()]"
      ],
      "metadata": {
        "id": "5_2-K2VR1eSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df[store_df.duplicated()]"
      ],
      "metadata": {
        "id": "RIP3YPcV2Dui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Missing values/Null values"
      ],
      "metadata": {
        "id": "_w_ISVAU2Tv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rossman_df.isnull().sum()"
      ],
      "metadata": {
        "id": "7PEBZAj_2ces"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.isnull().sum()"
      ],
      "metadata": {
        "id": "L_K2HuZn2hQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###What did you know about your dataset?"
      ],
      "metadata": {
        "id": "0okOFsIe21VQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In rossman store,There are 1017209 rows or observations and 9 columns in this dataset. There seems to be no null values in it. It has integer, datetime and object as data types.\n",
        "\n",
        "In store data file,There are 1115 rows and 10 columns. There are missing values in it and it is important to impute them with appropriate values in order to get good results later on.\n",
        "\n",
        "In rossman store data No missing value is present but in store data file in Out of 1115 entries there are missing values for the columns:\n",
        "\n",
        "CompetitionDistance- distance in meters to the nearest competitor store, the distribution plot would give us an idea about the distances at which generally the stores are opened and we would impute the values accordingly.\n",
        "\n",
        "CompetitionOpenSinceMonth- gives the approximate month of the time the nearest competitor was opened, mode of the column would tell us the most occuring month\n",
        "\n",
        "CompetitionOpenSinceYear- gives the approximate year of the time the nearest competitor was opened, mode of the column would tell us the most occuring month\n",
        "\n",
        "Promo2SinceWeek, Promo2SinceYear and PromoInterval are NaN wherever Promo2 is 0 or False as can be seen in the first look of the dataset. They can be replaced with 0."
      ],
      "metadata": {
        "id": "6CwPMGGw231a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2.Understanding Your Variables***"
      ],
      "metadata": {
        "id": "YQ13AdAI3d64"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Variable Description**\n",
        "\n",
        "**Rossmann Stores Data.csv - historical data including Sales**\n",
        "\n",
        "**store.csv - supplemental information about the store**\n",
        "\n",
        "Data fields\n",
        "Most of the fields are self-explanatory. The following are descriptions for those that aren't.\n",
        "\n",
        "**Id** - an Id that represents a (Store, Date) duple within the test set\n",
        "\n",
        "**Store** - a unique Id for each store\n",
        "\n",
        "**Sales** - the turnover for any given day (this is what you are predicting)\n",
        "\n",
        "**Customers** - the number of customers on a given day\n",
        "\n",
        "**Open** - an indicator for whether the store was open: 0 = closed, 1 = open\n",
        "\n",
        "**StateHoliday** - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None\n",
        "\n",
        "**SchoolHoliday** - indicates if the (Store, Date) was affected by the closure of public schools\n",
        "\n",
        "**StoreType** - differentiates between 4 different store models: a, b, c, d\n",
        "\n",
        "**Assortment** - describes an assortment level: a = basic, b = extra, c = extended\n",
        "\n",
        "**CompetitionDistance** - distance in meters to the nearest competitor store\n",
        "\n",
        "**CompetitionOpenSince[Month/Year]**- gives the approximate year and month of the time the nearest competitor was opened\n",
        "\n",
        "**Promo** - indicates whether a store is running a promo on that day\n",
        "\n",
        "**Promo2** - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating\n",
        "\n",
        "**Promo2Since[Year/Week]** - describes the year and calendar week when the store started participating in Promo2\n",
        "\n",
        "**PromoInterval** - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store\n"
      ],
      "metadata": {
        "id": "DUWGU4f23nAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Check Unique Values for variable.**"
      ],
      "metadata": {
        "id": "nbNJa5aw4APr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# change state holiday a,b, is equal to 1\n",
        "rossman_df['StateHoliday'].value_counts()"
      ],
      "metadata": {
        "id": "640BmO9ctZjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change datatype object into data object\n",
        "rossman_df['Date'].unique()"
      ],
      "metadata": {
        "id": "2GmYmxXWuO6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***3. Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CompetitionDistance - distance in metres to the nearest competitor store\n",
        "rossman_df['SchoolHoliday'].unique()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.isnull().sum()"
      ],
      "metadata": {
        "id": "TzIiqey2w-zD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "li = [\"DayOfWeek\", \"StateHoliday\", \"SchoolHoliday\"]\n",
        "\n",
        "for i in li:\n",
        "  print(i)\n",
        "  print(rossman_df[i].unique())\n",
        "  print('--------------------')"
      ],
      "metadata": {
        "id": "bPgyVm_pxYXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.nunique()"
      ],
      "metadata": {
        "id": "whPt4gE9yyZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# store dataset fill into null values I.E 0\n",
        "store_df['CompetitionDistance'] = store_df['CompetitionDistance'].fillna(0)\n",
        "store_df['CompetitionOpenSinceMonth'] = store_df['CompetitionOpenSinceMonth'].fillna(0)\n",
        "store_df['CompetitionOpenSinceYear'] = store_df['CompetitionOpenSinceYear'].fillna(0)\n",
        "store_df['Promo2SinceWeek'] = store_df['Promo2SinceWeek'].fillna(0)\n",
        "store_df['Promo2SinceYear'] = store_df['Promo2SinceYear'].fillna(0)\n",
        "store_df['PromoInterval'] = store_df['PromoInterval'].fillna(0)"
      ],
      "metadata": {
        "id": "O8bcg0YJzd3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.isna().sum()\n"
      ],
      "metadata": {
        "id": "GoE4fzN_0_tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df"
      ],
      "metadata": {
        "id": "Z14L47rs1HyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.merge(rossman_df, store_df, on='Store', how='left')"
      ],
      "metadata": {
        "id": "6oSyM5uM1Ti5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "38Rh0n3c2DAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change datatype object to int\n",
        "df.loc[df['StateHoliday'] == '0', 'StateHoliday'] = 0\n",
        "df.loc[df['StateHoliday'] == 'a', 'StateHoliday'] = 1\n",
        "df.loc[df['StateHoliday'] == 'b', 'StateHoliday'] = 2\n",
        "df.loc[df['StateHoliday'] == 'c', 'StateHoliday'] = 3\n",
        "# store the value with same column name i.e. StateHoliday with function astype\n",
        "df['StateHoliday'] = df['StateHoliday'].astype(int, copy=False)"
      ],
      "metadata": {
        "id": "XkVKkK0A25PR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change datatype object to int\n",
        "df.loc[df['Assortment'] == 'a', 'Assortment'] = 0\n",
        "df.loc[df['Assortment'] == 'b', 'Assortment'] = 1\n",
        "df.loc[df['Assortment'] == 'c', 'Assortment'] = 2\n",
        "# store the value with same column name i.e. Assortment with function astype\n",
        "df['Assortment'] = df['Assortment'].astype(int, copy=False)"
      ],
      "metadata": {
        "id": "0bKTQxfS4eie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change datatype object to int\n",
        "df.loc[df['StoreType'] == 'a', 'StoreType'] = 0\n",
        "df.loc[df['StoreType'] == 'b', 'StoreType'] = 1\n",
        "df.loc[df['StoreType'] == 'c', 'StoreType'] = 2\n",
        "df.loc[df['StoreType'] == 'd', 'StoreType'] = 3\n",
        "# store the value with same column name i.e. StoreType with function astype\n",
        "df['StoreType'] = df['StoreType'].astype(int, copy=False)"
      ],
      "metadata": {
        "id": "RP9X0Ad444f_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[['StateHoliday', 'Assortment', 'StoreType']].nunique())"
      ],
      "metadata": {
        "id": "bDBydeIl6S5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "Fif3M3Gv7BuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Sales\"].value_counts()"
      ],
      "metadata": {
        "id": "P0r1GLG47I27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code for changing format of date form object to datetime\n",
        "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
      ],
      "metadata": {
        "id": "dP7rjNkr7WdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code for change object into date format\n",
        "df['CompetitionOpenSinceMonth'] = pd.DatetimeIndex(df['Date']).month"
      ],
      "metadata": {
        "id": "-IUzvKD2FcYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code for change float into integer\n",
        "df['CompetitionOpenSinceYear'] = df['CompetitionOpenSinceYear'].astype(int)\n",
        "df['Promo2SinceYear'] = df['Promo2SinceYear'].astype(int)\n",
        "\n",
        "df['CompetitionDistance'] = df['CompetitionDistance'].astype(int)\n",
        "df['Promo2SinceWeek'] = df['Promo2SinceWeek'].astype(int)"
      ],
      "metadata": {
        "id": "JdCG1YgtFuFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "mKXIs8AaG-7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "tBbviwujGhR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().apply(lambda x: round(x, 2))"
      ],
      "metadata": {
        "id": "dx_uo5XLHiiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "plt.figure(figsize=(15,6))\n",
        "sns.pointplot(x = 'CompetitionOpenSinceYear', y = 'Sales', data=df, color='Red')\n",
        "sns.set_style(\"dark\")\n",
        "plt.title('Plot between Sales and CompetitionOpenSinceYear')"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From this chart we get insights that Sales is Highest During the year 1900 because for that time there are limited number of stores, hence the competition is very low. But as year pass, number of stores get incresed that means competition is also increased accordingly , hence sales got decreases year by year**"
      ],
      "metadata": {
        "id": "zds-bb5H5a3J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "plt.figure(figsize=(15,6))\n",
        "sns.pointplot(x = 'Promo2SinceYear', y = 'Sales', data=df, color='Red')\n",
        "sns.set_style(\"dark\")\n",
        "plt.title('Plot between Sales and Promo2SinceYear')"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From this graph we saw that sales of stores is effected which continues their promorion. The sales in 2013 and 2015 are very low inspite of promotion. The reason can be more competition year by year.**"
      ],
      "metadata": {
        "id": "zWql3lNB6nPL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "plt.figure(figsize=(15,6))\n",
        "sns.pointplot(x = 'DayOfWeek', y = 'Sales', data=df, color='Red')\n",
        "sns.set_style(\"dark\")\n",
        "plt.title('Plot between Sales and DayOfWeek')"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From this chart we get insights thet Maximum Sales on Day 1 which is Monday and the same is decreasing till Day 6 which is Saturday. As most of store are closed on Day  7 which is Sunday, so the Sales is closed to Zero.**"
      ],
      "metadata": {
        "id": "J96rf5wV7ehV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "plt.figure(figsize=(15,6))\n",
        "sns.pointplot(x = 'CompetitionOpenSinceMonth', y = 'Sales', data=df, color='Red')\n",
        "sns.set_style(\"dark\")\n",
        "plt.title('Plot between Sales and CompetitionOpenSinceMonth')"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From this chart we get insight that lowest sales in 1st month. As the new stores are open on the occasion of new year and compitation increases. and from 10th month sales get increases rapidly**"
      ],
      "metadata": {
        "id": "mtMhm-0GBxkK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Pie chart"
      ],
      "metadata": {
        "id": "grWDFSmm905O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "plot_storetype_sales = df.groupby('StoreType').Sales.sum().plot(kind='pie',figsize=(20,10),title='Sales distribution with storetype',autopct='%1.2f%%',colors= ['red','blue','green','orange'],startangle=90,shadow=False,subplots=True, labeldistance = 1, explode = [0.05,0.05,0.05,0.05])\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From this chart we get insight that storetype 0 has maximumm sales upto 53.89% sales of overall sales. and then storetype 3 has 2nd then storetype 2 and least sales count i.e 2.71% of storetype 1.**"
      ],
      "metadata": {
        "id": "bEgaV3XtC2f3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "\n",
        "plt.figure(figsize=(20,11))\n",
        "plot_storetype_sales = sns.barplot(x= 'Assortment', y= 'Sales', data=df)\n",
        "plt.title('Barplot for Sales Values on the basis of Assortment')"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From this chat we get insight that Assortment 1 Type has highest sales and and Assortment 0 has lowest sales.**"
      ],
      "metadata": {
        "id": "DqPP082MGtjD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "plt.figure(figsize=(20,11))\n",
        "sns.countplot(x= 'DayOfWeek', hue='Open', data=df, palette='viridis')\n",
        "plt.title('Store Daily Open Countplot')"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From this chart we get insight that most of the stores are opens a store on 1 to 6 days i.e Monday to Saturday of weekdays. and closes on 7th day i.e. on sunday**"
      ],
      "metadata": {
        "id": "ORv1Y8mGHt8E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "plt.figure(figsize=(20,11))\n",
        "sns.countplot(x= 'DayOfWeek', hue='Promo', data=df, palette='viridis')\n",
        "plt.title('Store Daily Promo Countplot')"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "plt.figure(figsize=(12,8))\n",
        "promo_sales = sns.barplot(x= 'Promo', y= 'Sales', data=df, palette='viridis')"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here 0 represents the stores which did not opt for promotion ans 1 represents for stores who opt for promotion. Those stores who took promotions their sales are high as compared to store who didn't took promotion**"
      ],
      "metadata": {
        "id": "yWX9isBfCMHH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **State Holiday**"
      ],
      "metadata": {
        "id": "zbj2UY3NC8rk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0 = Public Holiday, 1 = Easter Holiday, 2 = Christmas, 3 = None**"
      ],
      "metadata": {
        "id": "wE6GBn6dDCtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "plt.figure(figsize=(12,8))\n",
        "stateholiday_sales = sns.barplot(x= 'StateHoliday', y= 'Sales', data=df, palette='viridis')"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From this chart we get insight that sales is maximumm in public holiday and sales is minimumm there is no holiday. that means customers are more preferd to come in store in public holiday.**"
      ],
      "metadata": {
        "id": "mjSibxqEFwpH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **School Holiday**"
      ],
      "metadata": {
        "id": "6U_k-PXsD4rl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0 = 'Not Holiday', 1 = 'Holiday'**"
      ],
      "metadata": {
        "id": "6asGd5QHD-TB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "plt.figure(figsize=(12,8))\n",
        "stateholiday_sales = sns.barplot(x= 'SchoolHoliday', y= 'Sales', data=df, palette='viridis')"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We can observe that most of store remain closed during State Holidays. But it is interesting to note that the number of stores opened during School Holidays were more than that were opened during State Holidays. Another important thing to note is that the stores which were opened during School Holidays had more sales than normal**"
      ],
      "metadata": {
        "id": "itIgUleSEYgX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conclusion of EDA**\n",
        "\n",
        "1) From plot sales and competition Open Since Month shows sales go increasing from November and highest in month December.\n",
        "\n",
        "2) From plot Sales and day of week, Sales highest on Monday and start declining from Tuesday to Saturday and on Sunday Sales almost near toZero.\n",
        "\n",
        "3)Plot between Promotion and Sales shows that promotion helps in increasing Sales.\n",
        "\n",
        "4) Type of Store plays an important role in opening pattern of stores.\n",
        "\n",
        "5)All Type 'b' stores never closed except for refurbishment or other reason.\n",
        "\n",
        "6) All Type 'b' stores have comparatively higher sales and it mostly constant with peaks appears on weekends.\n",
        "\n",
        "7)ssortment Level 'b' is only offered at Store Type 'b'.\n",
        "\n",
        "8) We can observe that most of the stores remain closed during State Holidays. But it is interesting to note that the number of stores opened during School Holidays were more than that were opened during State Holidays."
      ],
      "metadata": {
        "id": "jJ2qIQCX60CU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "QZwfrPJrD9mx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1:\n",
        "\n",
        "# **Model 1(Excluding rows which has sales = 0)**"
      ],
      "metadata": {
        "id": "8z9Kj_f0EERa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2:\n",
        "# **2. Model2(By taking whole Dataset)**"
      ],
      "metadata": {
        "id": "K00YGqDjEWAG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Enfineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "jtmVdM_Y7T3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18,8))\n",
        "correlation =  df.corr()\n",
        "sns.heatmap(abs(correlation), annot=True, cmap='Reds', linewidth=2, fmt='2f')"
      ],
      "metadata": {
        "id": "pO2GCm_87k-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In above correlation plot color of the cell indicates the direction and strength of correaltion.**\n",
        "\n",
        "**a positive coorelation indicated by warm color such as red  and**\n",
        "\n",
        "**a neagtive coorelation indicated by cool color such as orange.**\n",
        "\n",
        "**the intensity of color represent the strength of a correlation.**"
      ],
      "metadata": {
        "id": "KQgP13CpHFcZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Multicollinearity**"
      ],
      "metadata": {
        "id": "b6ZV82HPHKEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "def calc_vif(X):\n",
        "\n",
        "    # Calculating VIF\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"variables\"] = X.columns\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "    return(vif)"
      ],
      "metadata": {
        "id": "URq2D-ad9r-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(df[[i for i in df.describe().columns if i not in ['Sales']]])"
      ],
      "metadata": {
        "id": "E4khV7gq9ve7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In above table we can see that VIF  value for column Promo2 and Promo2SinceYear is Higher. So we will drop either Promo2 or Promo2SinceYear and again check VIF value. Here we drop Promo2 column.**"
      ],
      "metadata": {
        "id": "CAvivpX-LAUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(df[[i for i in df.describe().columns if i not in ['Sales', 'Promo2']]])"
      ],
      "metadata": {
        "id": "ZAJnc_C5-IgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VIF factor below 10 is look good for Machine Learning Model.**"
      ],
      "metadata": {
        "id": "gHPhjDpq-P_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Analysis of Target Variables i.e. 'Sales'**"
      ],
      "metadata": {
        "id": "lvHpOkYtM4O1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(df['Sales']).hist(bins=5, color='red')"
      ],
      "metadata": {
        "id": "48Y_X0gRNEN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[(df.Open == 0) & (df.Sales == 0)].count()[0]"
      ],
      "metadata": {
        "id": "88k3LwMxNV38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**So we drop those store whose sales is 0 assuming that the stores were closed temporarily and this will help to train the model more accurately.**"
      ],
      "metadata": {
        "id": "44SR9lD_NtYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = df.drop(df[(df.Open == 0) & (df.Sales == 0)].index)"
      ],
      "metadata": {
        "id": "eDZ9fEvEOHK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.shape"
      ],
      "metadata": {
        "id": "4gKYhUgQOePI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df"
      ],
      "metadata": {
        "id": "abyleQUjOjZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In new_df dataset, column name 'PromoInterval' change into dummies it means that each new column will have a binary value (0 or 1).**"
      ],
      "metadata": {
        "id": "xSxjyxQlO0JL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = pd.get_dummies(new_df, columns=['PromoInterval'])"
      ],
      "metadata": {
        "id": "LlDVGO72OztJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df"
      ],
      "metadata": {
        "id": "ZxbJro4KPodj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.to_csv('cleandata.csv', index = False)"
      ],
      "metadata": {
        "id": "121nmXikP1R7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Training"
      ],
      "metadata": {
        "id": "m9aFnxPx_Lre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import zscore\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import r2_score as r2, mean_squared_error as mse\n",
        "import math\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import confusion_matrix,classification_report"
      ],
      "metadata": {
        "id": "3onbHLLo_RVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ML Model - 1 (Excluding rows which has sales = 0)**"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we two dataset, first one having sales = '0' rows and another excluding it. We will both the data and find the best model."
      ],
      "metadata": {
        "id": "bvqWpSB_A3zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining dependent variable\n",
        "dependent_variables = 'Sales'\n",
        "\n",
        "# Defining independent variable\n",
        "independent_variables = list(new_df.columns.drop(['Promo2SinceYear', 'Date', 'Sales']))"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list of independent variables\n",
        "independent_variables"
      ],
      "metadata": {
        "id": "anQvmXUiASfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the data of independent variable\n",
        "X = new_df[independent_variables].values\n",
        "\n",
        "# Creating the data of dependent variable\n",
        "Y = new_df[dependent_variables].values"
      ],
      "metadata": {
        "id": "pXs6MsDjBWlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)"
      ],
      "metadata": {
        "id": "JkGvzzQHAoxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we train the model\n",
        "reg = LinearRegression().fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "rMXgnVNRClzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the Regression Score i.e. R-squared value\n",
        "reg.score(X_train, Y_train)"
      ],
      "metadata": {
        "id": "vQidtAjxC09X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the coefficient of different independent variables\n",
        "reg.coef_"
      ],
      "metadata": {
        "id": "XzNFkjd9DQqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the intercept of different independent columns\n",
        "reg.intercept_"
      ],
      "metadata": {
        "id": "2qPR0r-6DcBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting Dependable Variable with Test Dataset i.e. 20%\n",
        "Y_pred = reg.predict(X_test)\n",
        "Y_pred"
      ],
      "metadata": {
        "id": "ArrEzKceEHbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Original Test Dependent Value\n",
        "Y_test"
      ],
      "metadata": {
        "id": "ZtAgyVX0DrVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on Train Dataset\n",
        "Y_pred_train = reg.predict(X_train)\n",
        "Y_pred_train"
      ],
      "metadata": {
        "id": "_BuAXcbNEwnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependent Variable with Train Dataset i.e. 80%\n",
        "Y_train"
      ],
      "metadata": {
        "id": "_Flg4fE6FAyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating MSE & RMSE for Test Prediction\n",
        "MSE = mean_squared_error(Y_test, Y_pred)\n",
        "print(\"MSE :\", MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\", RMSE)"
      ],
      "metadata": {
        "id": "xTkhvaeRFQAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2 = r2_score(Y_test, Y_pred)\n",
        "print(\"r2 :\", r2)"
      ],
      "metadata": {
        "id": "-NAQIHclGG8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(zip(Y_test, Y_pred), columns = ['actual', 'pred'])"
      ],
      "metadata": {
        "id": "BM5RG1tKGioO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **LASSO**"
      ],
      "metadata": {
        "id": "GMk7CablHeB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "L1 = Lasso(alpha = 0.4, max_iter=10000, selection='cyclic', tol=0.0001)"
      ],
      "metadata": {
        "id": "B3vhoThuHmJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L1.fit(X_train , Y_train)"
      ],
      "metadata": {
        "id": "zj1fDdJaIIaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred_lasso = L1.predict(X_test)"
      ],
      "metadata": {
        "id": "7l4TCEBMIVdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L1.score(X_test, Y_test)"
      ],
      "metadata": {
        "id": "ri-tMSizIfz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_scores = cross_val_score(L1, X,Y, cv = 10)\n",
        "mean_cv_score = cv_scores.mean()"
      ],
      "metadata": {
        "id": "_Bjd4vWiI1Hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_scores"
      ],
      "metadata": {
        "id": "ZUsOdf3XI0S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_cv_score"
      ],
      "metadata": {
        "id": "NYC1fwuVJVqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "# define the range of alpha values to test\n",
        "parameters = {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5]}\n",
        "\n",
        "# perform grid search to find the best alpha value\n",
        "lasso_cv = GridSearchCV(L1, parameters, cv=5)\n",
        "lasso_cv.fit(X, Y)"
      ],
      "metadata": {
        "id": "FdEHevXUKqEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the best alpha value and corresponding score\n",
        "best_alpha_lasso = lasso_cv.best_params_['alpha']\n",
        "best_score_lasso= lasso_cv.best_score_"
      ],
      "metadata": {
        "id": "B5HQSL2rK143"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_alpha_lasso\n"
      ],
      "metadata": {
        "id": "Fc8qdy8FK55u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_score_lasso"
      ],
      "metadata": {
        "id": "8Yc4FFPlK52L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(zip(Y_test, Y_pred_lasso), columns=['actual', 'pred'])"
      ],
      "metadata": {
        "id": "uxlywI7fLoEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L2 = Ridge(alpha=0.5)"
      ],
      "metadata": {
        "id": "hztVLGyoMSmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L2.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "wIMgyTOMMSkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L2.predict(X_test)"
      ],
      "metadata": {
        "id": "XEIQazKQMSho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L2.score(X_test, Y_test)\n"
      ],
      "metadata": {
        "id": "OBlqlmmsMSei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "\n",
        "ridge = Ridge(max_iter=10000, solver='auto')\n",
        "\n",
        "# define the range of alpha values to test\n",
        "parameters = {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5]}\n",
        "\n",
        "# perform grid search to find the best alpha value\n",
        "ridge_cv = GridSearchCV(L2, parameters, cv=5)\n",
        "ridge_cv.fit(X, Y)\n",
        "\n",
        "# extract the best alpha value and corresponding score\n",
        "best_alpha = ridge_cv.best_params_['alpha']\n",
        "best_score = ridge_cv.best_score_\n",
        "\n",
        "# perform cross-validation with the best alpha value\n",
        "ridge_best = Ridge(alpha=best_alpha, max_iter=10000, solver='auto')\n",
        "cv_scores = cross_val_score(ridge_best, X, Y, cv=5)\n",
        "\n",
        "# find the maximum score and corresponding alpha value\n",
        "max_score = cv_scores.max()\n",
        "max_alpha = best_alpha\n",
        "\n",
        "print(\"Best alpha value: \", best_alpha)\n",
        "print(\"Best score: \", best_score)\n",
        "print(\"Maximum CV score: \", max_score)\n",
        "print(\"Corresponding alpha value: \", max_alpha)\n"
      ],
      "metadata": {
        "id": "y1wkwd42MSbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Elastic Net**"
      ],
      "metadata": {
        "id": "p3QmRPjTNZx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "# define the Elastic Net model\n",
        "elastic_net = ElasticNet(max_iter=10000)\n",
        "\n",
        "# define the range of alpha and l1_ratio values to test\n",
        "parameters = {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5], 'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]}\n",
        "\n",
        "# perform grid search to find the best alpha and l1_ratio values\n",
        "elastic_net_cv = GridSearchCV(elastic_net, parameters, cv=5)\n",
        "elastic_net_cv.fit(X_train, Y_train)\n",
        "\n",
        "# extract the best alpha and l1_ratio values and corresponding score\n",
        "best_alpha = elastic_net_cv.best_params_['alpha']\n",
        "best_l1_ratio = elastic_net_cv.best_params_['l1_ratio']\n",
        "best_score = elastic_net_cv.best_score_\n",
        "\n",
        "# create an Elastic Net model with the best hyperparameters\n",
        "elastic_net_best = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio, max_iter=10000)\n",
        "elastic_net_best.fit(X_train, Y_train)\n",
        "\n",
        "# evaluate the model on the testing set\n",
        "test_score = elastic_net_best.score(X_test, Y_test)\n",
        "\n",
        "print(\"Best alpha value: \", best_alpha)\n",
        "print(\"Best l1_ratio value: \", best_l1_ratio)\n",
        "print(\"Best score: \", best_score)\n",
        "print(\"Test score: \", test_score)\n"
      ],
      "metadata": {
        "id": "bg4-R9FFMSYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Decision Tree**"
      ],
      "metadata": {
        "id": "JJXYKeDrOY0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_mean = df[dependent_variables].mean()"
      ],
      "metadata": {
        "id": "rmy1_Us9MSVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_mean\n"
      ],
      "metadata": {
        "id": "Ki6tzRMmOwWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_mean_new = new_df[dependent_variables].mean()"
      ],
      "metadata": {
        "id": "I6ko9GiVQLqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_mean_new"
      ],
      "metadata": {
        "id": "QGxYUu8ZQLeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree=DecisionTreeRegressor(max_depth=5)\n",
        "decision_tree.fit(X_train, Y_train)\n",
        "y_pred_dt = decision_tree.predict(X_test)\n",
        "y_train_dt = decision_tree.predict(X_train)\n",
        "#print('dt_regressor R^2: ', r2(v_test,v_pred))\n",
        "MSE  = mean_squared_error(Y_test, y_pred_dt)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "RMPSE=RMSE/sales_mean_new\n",
        "print(\"RMPSE :\",RMPSE)\n",
        "\n",
        "r2 = r2_score(Y_test, y_pred_dt)\n",
        "print(\"R2 :\" ,r2)"
      ],
      "metadata": {
        "id": "5T_jsQZTQhVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **MODEL 2 (By taking whole Dataset)**\n",
        "\n",
        "\n",
        "**In final1 dataset,column name 'PromoInterval' change into dummies it means that each new column will have a binary value (0 or 1).**"
      ],
      "metadata": {
        "id": "EjLchJ_RWY0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df, columns=['PromoInterval'])"
      ],
      "metadata": {
        "id": "lovkoNn_Wh1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "RnixPGAAWw0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We defined dependent variable and convert them into arrays**"
      ],
      "metadata": {
        "id": "lOzCkXVzW3aL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining dependent variable\n",
        "dep_var = 'Sales'\n",
        "\n",
        "# defining independent variable\n",
        "indep_var = df.columns.drop(['Store', 'Promo2SinceYear','Date','Sales'])"
      ],
      "metadata": {
        "id": "MM6iqLkCXHrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indep_var"
      ],
      "metadata": {
        "id": "3XYo6foXXppq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the data of independent variable\n",
        "U = df[indep_var].values\n",
        "# Create data of dependent variable\n",
        "V = df[dep_var].values"
      ],
      "metadata": {
        "id": "CmkucXKLXy5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "V"
      ],
      "metadata": {
        "id": "zWC7NFeTYIbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "U"
      ],
      "metadata": {
        "id": "RRKFVgtNYLPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[indep_var]"
      ],
      "metadata": {
        "id": "OXcX5GDtYPPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset\n",
        "U_train, U_test, V_train, V_test = train_test_split(U, V, test_size=0.2, random_state=0)\n",
        "print(U_train.shape)\n",
        "print(V_train.shape)"
      ],
      "metadata": {
        "id": "sx6Ui3KkYlLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **LINEAR REGRESSION**"
      ],
      "metadata": {
        "id": "FJQ8o6CbaUFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scling the x values\n",
        "scaler=StandardScaler()\n",
        "\n",
        "U_train = scaler.fit_transform(U_train)\n",
        "U_test = scaler.transform(U_test)"
      ],
      "metadata": {
        "id": "qD5z_9t-acoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting the data into Lineat Regression Model\n",
        "linear_regression = LinearRegression()\n",
        "linear_regression.fit(U_train, V_train)"
      ],
      "metadata": {
        "id": "66-ZG3ZVagnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "V_pred=linear_regression.predict(U_test)\n",
        "V_pred"
      ],
      "metadata": {
        "id": "pt9YRaY8am5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_regression.score(U_train, V_train)"
      ],
      "metadata": {
        "id": "uixzRdQxarmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regression_DataFrame = pd.DataFrame(zip(V_test, V_pred), columns = ['actual', 'pred'])\n",
        "regression_DataFrame"
      ],
      "metadata": {
        "id": "nM5VbuG9a0nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "MSE  = mean_squared_error(V_test, V_pred)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "RMPSE=RMSE/sales_mean\n",
        "print(\"RMPSE :\",RMPSE)\n",
        "\n",
        "r2 = r2_score(V_test, V_pred)\n",
        "print(\"R2 :\" ,r2)"
      ],
      "metadata": {
        "id": "dZxwgUuAbYwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **DESICION TREE**"
      ],
      "metadata": {
        "id": "Da77ejMhbxQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree=DecisionTreeRegressor(max_depth=5)\n",
        "decision_tree.fit(U_train, V_train)\n",
        "V_pred_dt = decision_tree.predict(U_test)\n",
        "V_train_dt = decision_tree.predict(U_train)\n",
        "#print('dt_regressor R^2: ', r2(v_test,v_pred))\n",
        "MSE  = mean_squared_error(V_test, V_pred_dt)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "RMPSE=RMSE/sales_mean\n",
        "print(\"RMPSE :\",RMPSE)\n",
        "\n",
        "r2 = r2_score(V_test, V_pred_dt)\n",
        "print(\"R2 :\" ,r2)"
      ],
      "metadata": {
        "id": "ptplPly2b3EW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree_DataFrame = pd.DataFrame(zip(V_test, V_pred_dt), columns=['actual', 'pred'])\n",
        "decision_tree_DataFrame"
      ],
      "metadata": {
        "id": "IO3ZfNPScM9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Create a random forest regressor with n_estimators=500, max_depth=8, and n_jobs=2\n",
        "random_forest = RandomForestRegressor(n_estimators=500, max_depth=8, n_jobs=2)\n",
        "\n",
        "# Fit the random forest to the training data\n",
        "random_forest.fit(U_train, V_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "V_pred_rf = random_forest.predict(U_test)\n",
        "\n",
        "# Calculate the mean squared error (MSE) between the predicted and actual values\n",
        "MSE = mean_squared_error(V_test, V_pred_rf)\n",
        "print(\"MSE:\", MSE)\n",
        "\n",
        "# Calculate the root mean squared error (RMSE)\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE:\", RMSE)\n",
        "\n",
        "# Calculate the root mean squared percentage error (RMPSE)\n",
        "sales_mean = np.mean(V_test)\n",
        "RMPSE = RMSE / sales_mean\n",
        "print(\"RMPSE:\", RMPSE)\n",
        "\n",
        "# Calculate the coefficient of determination (R2 score)\n",
        "r2 = r2_score(V_test, V_pred_rf)\n",
        "print(\"R2:\", r2)\n"
      ],
      "metadata": {
        "id": "pQN7h8I4cn06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "\n",
        "adaboost = AdaBoostRegressor(n_estimators=500, learning_rate=0.01)\n",
        "adaboost.fit(U_train, V_train)\n",
        "V_pred_ada = adaboost.predict(U_test)\n",
        "\n",
        "MSE = mean_squared_error(V_test, V_pred_ada)\n",
        "print(\"MSE :\", MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\", RMSE)\n",
        "\n",
        "RMPSE = RMSE/sales_mean\n",
        "print(\"RMPSE :\", RMPSE)\n",
        "\n",
        "r2 = r2_score(V_test, V_pred_ada)\n",
        "print(\"R2 :\", r2)\n"
      ],
      "metadata": {
        "id": "PsQ48xnRctKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "xgboost = xgb.XGBRegressor(n_estimators=500, max_depth=8, n_jobs=2)\n",
        "xgboost.fit(U_train, V_train)\n",
        "V_pred_xgb = xgboost.predict(U_test)\n",
        "\n",
        "\n",
        "\n",
        "MSE = mean_squared_error(V_test, V_pred_xgb)\n",
        "print(\"MSE :\", MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\", RMSE)\n",
        "\n",
        "RMPSE = RMSE/sales_mean\n",
        "print(\"RMPSE :\", RMPSE)\n",
        "\n",
        "r2 = r2_score(V_test, V_pred_xgb)\n",
        "print(\"R2 :\", r2)\n"
      ],
      "metadata": {
        "id": "0nFYHEo7r4An"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "1vNiNKmldXi2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We saw that Sales column contains 172817 rows with 0 sale. So we created a   new dataframe in which we removed 0 sales rows and tried to train our model. We used various algorithms and got accuracy score around **74%.**\n",
        "\n",
        "\n",
        "\n",
        "We were also curious about the total dataset(including Sales = 0 rows). So we trained another model using various algorithms and we got accuracy near about **98%** which is far better than previous model.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "So we came to conclusion that removing sales=0 rows actually removes lot of information from dataset as it has **172817**   rows which is quite large and therefore we decided not to remove those values.We got our best r score from **Random Forest model,Graident boosting technique like  adaboost ,Xgboost**,we tried taking an optimum parameter so that our model doesnt overfit."
      ],
      "metadata": {
        "id": "bj3KRzwpdcBH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}